# head.py (Phi√™n b·∫£n cu·ªëi c√πng)

import torch
import torchvision.transforms as T
from PIL import Image
from ultralytics.nn.tasks import DetectionModel
import yaml

# ======== 1. Load TO√ÄN B·ªò ki·∫øn tr√∫c, nh∆∞ng ch·ªâ load tr·ªçng s·ªë part1 ========
print("üöÄ Loading full architecture for head...")
# S·ª≠ d·ª•ng file yaml g·ªëc
cfg = yaml.safe_load(open('head.yaml', 'r', encoding='utf-8'))
model = DetectionModel(cfg)

print("   Loading state_dict for part1...")
state_dict_part1 = torch.load('part1.pt', map_location='cpu' , weights_only=True)
model.load_state_dict(state_dict_part1, strict=False)  # B·ªè qua c√°c key b·ªã thi·∫øu c·ªßa part2
model.eval()
print("   ...Done.")

# ======== 2. Load and preprocess image ========
print("üñºÔ∏è Loading and preprocessing image...")
img = Image.open('image.png').convert('RGB')
transform = T.Compose([
    T.Resize((640, 640)),
    T.ToTensor(),
])
x = transform(img).unsqueeze(0)
print(f"   Input image tensor shape: {x.shape}")


# ======== 3. Vi·∫øt l·∫°i h√†m forward ƒë·ªÉ ch·ªâ ch·∫°y qua part1 ========
def forward_head(head_model, x_in):
    # Ch·ªâ ch·∫°y qua c√°c l·ªõp 0 v√† 1
    split_index = 4
    y = {}  # L∆∞u output trung gian

    # Ch·∫°y qua c√°c l·ªõp c·ªßa head
    for layer in head_model.model[:split_index]:
        if layer.f != -1:  # L·∫•y input t·ª´ c√°c l·ªõp tr∆∞·ªõc n·∫øu c·∫ßn
            x_in = y[layer.f] if isinstance(layer.f, int) else [y[j] for j in layer.f]

        x_in = layer(x_in)  # Ch·∫°y forward
        y[layer.i] = x_in  # L∆∞u output

    return x_in  # Tr·∫£ v·ªÅ output c·ªßa l·ªõp cu·ªëi c√πng trong head


# ======== 4. Th·ª±c hi·ªán forward v√† l∆∞u feature map ========
print("üß† Performing custom forward pass on head...")
with torch.no_grad():
    feature_map = forward_head(model, x)

print(f"   Output feature map shape: {feature_map.shape}")
torch.save(feature_map, 'feature_map.pt')
print("\n‚úÖ Saved single feature map to 'feature_map.pt'")